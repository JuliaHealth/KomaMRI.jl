##########################
## SIMULATION FUNCTIONS ##
##########################
gpu(x) = CUDA.has_cuda_gpu() ? CuArray(x) : x
print_gpus() = begin
	@info "$(length(devices())) CUDA capable devices."
	for d = devices()
		@info name(d)
	end
end
"""
	run_sim2D(obj,seq,t)

Simulates MRI sequence `seq` on the Phantom `obj` for time points `t`.
It calculates S(t) = âˆ« Ï(x,t) exp(ð’Š Ï•(x,t)) dx.
"""
function run_sim2D_spin(obj::Phantom,seq::Sequence,t::Array{Float64,1};Ï•0::Array{Float64,1}=0.)
	ð’Š = 1im; Random.seed!(1)
	t = reshape(t,1,length(t)); Î”t = t[2]-t[1]
    sz = size(obj)
    Nsz, Nt = length(sz), length(t)
	#DIFFUSION
	if !all(obj.DÎ»1 .== 0) && !all(obj.DÎ»2 .== 0) #No diff optimization
		Î·x = sqrt.(2Î”t.*obj.DÎ»1).*randn(sz...,Nt)
		Î·y = sqrt.(2Î”t.*obj.DÎ»2).*randn(sz...,Nt)
		Î·xp = cumsum(Î·x.*cos.(obj.DÎ¸).-Î·y.*sin.(obj.DÎ¸),dims=Nsz+1)
		Î·yp = cumsum(Î·y.*cos.(obj.DÎ¸).+Î·x.*sin.(obj.DÎ¸),dims=Nsz+1)
	else
		Î·xp = 0
		Î·yp = 0
	end
	#SCANNER
    Gx = get_grad(seq,1,t) |> gpu
	Gy = get_grad(seq,2,t) |> gpu 
	#SIMULATION
	Ï•0 = Ï•0 |> gpu
    xt = obj.x .+ obj.ux(obj.x,obj.y,t) .+ Î·xp |> gpu
    yt = obj.y .+ obj.uy(obj.x,obj.y,t) .+ Î·yp |> gpu
    if is_DAC_on(seq,t) #ACQ OPTIMIZATION
		Ï• = Ï•0 .+ (2Ï€*Î³*Î”t).*cumsum(xt.*Gx.+yt.*Gy, dims=Nsz+1) 
	else
		Ï• = Ï•0 .+ (2Ï€*Î³*Î”t).*sum(xt.*Gx.+yt.*Gy, dims=Nsz+1) 
	end
	#SIGNAL
	t = t		 |> gpu
	Ï = obj.Ï	 |> gpu
	Î”w = obj.Î”w  |> gpu
	T2 = obj.T2  |> gpu
    S = sum(Ï.*exp.(-ð’Š.*(Ï• .+ Î”w.*t).-t./T2 ), dims=1:Nsz)[:]
    Array(S), Array(Ï•[:,end])
end
"""Divides a list of indices 1:N in k groups"""
function kfoldperm(N,k; type="random")
	n,r = divrem(N,k)
	b = collect(1:n:N+1)
	for i in 1:length(b)
		b[i] += i > r ? r : i-1
	end
	if type=="random"
		p = randperm(N)
	elseif type=="ordered"
		p = 1:N
	end
	return [p[r] for r in [b[i]:b[i+1]-1 for i=1:k]]
end

"""
Implementation in multiple threads by separation the spins in N_parts.
"""
function run_sim2D_spin_parallel(obj::Phantom,seq::Sequence,t::Array{Float64,1};
	Ï•0::Array{Float64,1}=0., N_parts::Int= CUDA.has_cuda_gpu() ? 1 : Threads.nthreads())

	Nt, Ns = length(t), prod(size(obj))
	S = zeros(ComplexF64, Nt)
	
    #addprocs(N_parts)
	parts = kfoldperm(Ns, N_parts, type="ordered") 

	@threads for p âˆˆ parts
		aux, Ï•0[p] = run_sim2D_spin(obj[p],seq,t;Ï•0=Ï•0[p])
		S .+= aux
		aux = nothing
	end
    S, Ï•0
end

"""Divides time steps in N_parts blocks. Decreases RAM usage in long sequences."""
function run_sim2D_times_iter(obj::Phantom,seq::Sequence, t::Array{Float64,1};N_parts::Int=16)
    N, Ns = length(t), prod(size(obj))
	S = zeros(ComplexF64, N)
	Ï•0 = zeros(size(obj))

    parts = kfoldperm(N,N_parts,type="ordered")
    println("Starting simulation with Nspins=$Ns and Nt=$N")
    
	@showprogress for p âˆˆ parts
		S[p], Ï•0 =  run_sim2D_spin_parallel(obj, seq, t[p]; Ï•0)
	end
    S
end
